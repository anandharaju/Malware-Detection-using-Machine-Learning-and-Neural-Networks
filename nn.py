import tensorflow as tf
import sklearn.ensemble as ek
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
import pandas as pd
import numpy
from sklearn.utils import shuffle

#data pre-processing
numpy.random.seed(1)
dataset = pd.read_csv('data.csv',sep='|', low_memory=False)
print("Dataset Shape before shuffling :", dataset.shape)
dataset = shuffle(dataset)
print("Dataset Shape after shuffling  :", dataset.shape)

#for name, values in dataset.iteritems():
#    print('{name}: {value}'.format(name=name, value=values[138046]))


X = dataset.drop(['Name','md5','legitimate'],axis=1).values
y = dataset[['legitimate']].values

print("X Shape: "+str(X.shape))
print("y Shape: "+str(y.shape))

print("Dim Reduction")
#dimensionality reduction		
extratrees = ek.ExtraTreesClassifier().fit(X,y)
model = SelectFromModel(extratrees, prefit=True)
X_new = model.transform(X)
#X_new = X
feature_count = X_new.shape[1]
label_count = 1

print("Splitting train/test set")
X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)
features = []
index = numpy.argsort(extratrees.feature_importances_)[::-1][:feature_count]

#for f in range(feature_count):
#	print("%d. feature %s (%f)" % (f + 1, dataset.columns[2+index[f]], extratrees.feature_importances_[index[f]]))
#	features.append(dataset.columns[2+f])

print("Features shape", str(len(features)))

# inputs
#batch_size = 100
#training_epochs = 1000
learning_rate = 0.01
hidden_layers = feature_count - 1
#cost_history = np.empty(shape=[1],dtype=float)

print("Tensors creation")

X = tf.placeholder(tf.float32,[None,feature_count])
Y = tf.placeholder(tf.float32,[None,label_count])
is_training=tf.Variable(True,dtype=tf.bool)

print("Defining Layer")
# models
initializer = tf.contrib.layers.xavier_initializer()
h0 = tf.layers.dense(X, hidden_layers, activation=tf.nn.relu, kernel_initializer=initializer)
# h0 = tf.nn.dropout(h0, 0.95)
h1 = tf.layers.dense(h0, label_count, activation=None)

predicted = tf.nn.sigmoid(h1)
correct_pred = tf.equal(tf.round(predicted), Y)
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=h1)
cost = tf.reduce_mean(cross_entropy)
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

# next-batch
'''def next_batch(num):
  global count
  x,y = X_train[count:count+num],y_train[count:count+num]
  count = (count+num)%len(X_train)
  tf.print(count)
  return x,y'''


print("Starting Tensorflow session")
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    for step in range(501):
        sess.run(optimizer,feed_dict={X: X_train, Y:y_train})
        #ans = sess.run(predicted,feed_dict={X:X_train,Y:y_train})
        #print(ans[:10])
        loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={X: X_train, Y: y_train})
        #cost_history = np.append(cost_history, acc)
        if step % 500 == 0:
            #print(ans[:10])
            print("Step: {:10}\tLoss: {:.3f}\tAcc: {:.2%}".format(step, loss, acc))
            
    # Test model and check accuracy
    print('Test Accuracy:', sess.run(accuracy, feed_dict={X: X_test, Y: y_test}))
    #predict = sess.run(predicted,feed_dict={X:X_test})  
