import os
import pandas
import numpy
import pickle
import pefile
import pymongo
import sklearn.ensemble as ek
from sklearn import  tree, linear_model
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
from sklearn.externals import joblib
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.pipeline import make_pipeline
from sklearn import preprocessing
from sklearn import svm
from sklearn.linear_model import LinearRegression

from malware_class import Refine

dataset = pandas.read_csv('data.csv',sep='|', low_memory=False)

refine = Refine(dataset)
X,y = refine.preprocessing()

extratrees = ek.ExtraTreesClassifier().fit(X,y)

class Model:
	
	def __init__(self,X,y):
		self.X = X
		self.y = y
		
	def preprocessing(self):
		
		#extratrees = ek.ExtraTreesClassifier().fit(self.X,self.y)
		model = SelectFromModel(extratrees, prefit=True)
		X_new = model.transform(self.X)
		nbfeatures = X_new.shape[1]
		print(X.shape)
		print(X_new.shape)
		return(X_new,nbfeatures)
		
	def training(self):
		
		temp_model = Model(X,y)
		X_new,nbfeatures = temp_model.preprocessing()
		
		X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)
		features = []
		index = numpy.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]

		for f in range(nbfeatures):
			print("%d. feature %s (%f)" % (f + 1, dataset.columns[2+index[f]], extratrees.feature_importances_[index[f]]))
			features.append(dataset.columns[2+f])

		models = { "DecisionTree":tree.DecisionTreeClassifier(max_depth=10),
				 "RandomForest":ek.RandomForestClassifier(n_estimators=50),
				 "Adaboost":ek.AdaBoostClassifier(n_estimators=50),
				 "GradientBoosting":ek.GradientBoostingClassifier(n_estimators=50),
				 "GNB":GaussianNB(),
				 "LinearRegression":LinearRegression()   
					}	
		print(features)			
		results = {}
		for algo in models:
			clf = models[algo]
			clf.fit(X_train,y_train)
			score = clf.score(X_test,y_test)
			print ("%s : %s " %(algo, score))
			results[algo] = score
			
		winner = max(results, key=results.get)
		print(joblib.dump(models[winner],'classifier/classifier.pkl'))
		open('classifier/features.pkl', 'wb').write(pickle.dumps(features))
		clf = models[winner]
		res = clf.predict(X_new)
		mt = confusion_matrix(y, res)
		print("False positive rate : %f %%" % ((mt[0][1] / float(sum(mt[0])))*100))
		print('False negative rate : %f %%' % ( (mt[1][0] / float(sum(mt[1]))*100)))
		
		
def Exec():
	model = Model(X,y)
	model.training()
	
if __name__ == "__main__":Exec()
